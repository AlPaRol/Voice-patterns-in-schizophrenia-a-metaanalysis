---
word_document: default
author: "RF"
date: "3 marzo 2018"
output:
  html_document: default
  word_document: default
html_document: default
title: "Correlation meta-analysis"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# TO DO
## Clean up table (outsite of R) and consistently change names here


```{r}
# Clean up the R environment

rm(list=ls())

# Load the necessary packages. If not present, it installs them.
if (!require("pacman")) install.packages("pacman")
if (!require("brmstools")) devtools::install_github("mvuorre/brmstools")
pacman::p_load(tidyverse,brms,metafor,robumeta,boot,readxl,tidybayes,stringi,Hmisc) 

# Load the data (same folder as the script)

#setwd("C:/Users/albin/Dropbox/Voice in Schizophrenia - A metaanalysis/ANALISI")

d <- as.data.frame(read_excel("Matrix_MetaAnalysis_Correlation_updated290719.xlsx"))


# Select relevant variables 

d <- d %>% select(X__1:X__95)
colnames(d) <- d[1,]
d <- d[-1,]
d$ACOUST_ANA_DESCR <- NULL
d$DESCRIPTION <- NULL
d$COMMENTS <- NULL
d$SAMPLE_SIZE_SZ <- as.numeric(d$SAMPLE_SIZE_SZ)
d$FEMALE_SZ <- as.numeric(d$FEMALE_SZ)
d$Task <- d$TYPE_OF_TASK


# Exclude schizotypy for the main analysis

d <- d %>% subset(DIAGNOSIS == "SZ")

```
## 

```{r}


 # Functions for calculating bmrs model 

brmsFun<-function(formula,data,prior=FALSE,priorSpec=NULL,plot=T){
  if (prior==FALSE){
    m <- brm(formula, 
             data = data, iter = 8000, chains=2, cores = 2,
             save_mevars = T,
             control= list(adapt_delta = 0.999,max_treedepth=20))
  } else {
    m <- brm(formula, 
             data = data, iter = 8000, 
             chains=2, 
             cores = 2,
             save_mevars = T,
             prior=priorSpec,
             sample_prior = T,
             control= list(adapt_delta = 0.999,max_treedepth=20))
  }
  m <- add_ic(m,ic = "loo")
  print(pp_check(m,nsamples=200))
  if (plot==T){
    print(plot(m))
  }
  return(m)
}


brmFitAndSave <- function(formula,Name,d,prior=F,priorSpec=prior_ma){
  m <- brmsFun(formula,d,prior=F,priorSpec=prior_ma,plot=F)
  save(m, file = paste0(Name,collapse=""))
  return(m)
}


# Function for reporting total number of studies and research included in the meta-analysis, total number of partcipants and median sample size for each acoustic feature meta-analyzed  


DataReportES <- function(d){
  
  d0 <- d %>% subset(complete.cases(EffectSize))
  d1 <- d0 %>% subset(!duplicated(Population))
  d2 <- d0 %>% subset(!duplicated(ID))
  TotalParticipantsASD <- sum(d1$SAMPLE_SIZE_SZ,na.rm=T)
  TotalFemaleASD <- sum(d1$FEMALE_SZ,na.rm=T)
  MedianParticipantsASD <- median(d1$SAMPLE_SIZE_SZ,na.rm=T)
  
  print(paste0("The meta-analysis included ", nrow(d0), " studies (", nrow(d2), " articles) for a total of ", TotalParticipantsASD, " participants with schizophrenia (", TotalFemaleASD," female ones). The median number of participants with schizophrenia was ", MedianParticipantsASD,"."))
  
}


# Now the function to perform the meta-analysis 

MetaAnalysisCorrelation <- function(d,Name="alogia and pitch variability",FeatureCorrelation){
  
   # Create ad hoc variable for the relevant acoustic features
  
  d$FeatureCorrelation <- d[,FeatureCorrelation]

     
   # Drop irrelevant variables and rename
  
   d = select(
    d,
    ID = ArticleID,
    Year = Year_publication,
    SAMPLE_SIZE_SZ,
    FEMALE_SZ,
    Population=StudyID,
    DiagnosisDetails=DIAGNOSIS,
    Task=TYPE_OF_TASK,
    Authors=Article,
    FeatureCorrelation
  )
  
#Let's calculate standardized effect sizes, variance and standard errors
   
   
  d = escalc('COR', ri = as.numeric(FeatureCorrelation), ni = as.numeric(SAMPLE_SIZE_SZ), data = d)
  d$StandardError=summary(d)$sei
  d = d %>% dplyr::rename(EffectSize=yi,Variance=vi)
  
  d <- d %>%  subset(!is.na(EffectSize))
  
  
  # create new column ("new_auhtors") in the matrix to order study by task (to use later in the Bayesian forest plot)
  
  new.column = as.vector(ave(d$Task, d$Task, FUN=seq_along))
  d=cbind(as.data.frame(d), new.column)
  d$new2 <- with(d, paste0(Task,"_", new.column))
  d$Task <- factor(d$Task)
  d <- d[
  with(d, order(d$Task, d$new2)),
  ]
  d$IDOS <- seq.int(nrow(d))
  d$IDOS <- sprintf("%02d", d$IDOS)
  d$new_authors <- with(d, paste0(d$IDOS,"_", Authors))
  
  DataReportES(d)
  
  
  # and now data modelling
  
  if (nrow(d)==0){
    MetaPrior=data.frame(Name,Mean=NA,SE=NA,SD=NA)
    print("Not enough data points") 
  } else if (nrow(d)==1){
    
    MetaPrior=data.frame(
      Name,
      Mean=d$EffectSize,
      SE=d$StandardError,
      SD=sqrt(d$Variance))
  } else if (nrow(d)>1){
    
    # Random Effects Model
    
    MetaforM <-  rma.mv(EffectSize, Variance, random = ~ 1 | ID, method = "ML", data = d, slab=Authors)
    # N.B. tau squared in rma.mv is called sigma squared.
    #resCI <- predict(MetaforM, digits=3)
    #resCI2 <- confint(MetaforM)
    
    ggplot_Freq_Forest <- function(m=MetaforM,d){
    
    # add effect size to ggplot_matrix
    SumSize <- toString(MetaforM$b)
    SumSize <- round(as.numeric(SumSize), digits =2)
    SumSize.ci.lb <- toString(MetaforM$ci.lb)
    SumSize.ci.lb <- round(as.numeric(SumSize.ci.lb), digits =2)
    SumSize.ci.ub <- toString(MetaforM$ci.ub)
    SumSize.ci.ub <- round(as.numeric(SumSize.ci.ub), digits =2)
    SumSize_tot <- paste0(SumSize," [",SumSize.ci.lb,", ",SumSize.ci.ub,"]")
    
    # create new matrix for the Bayesian plot function
    
    d2 <- d[,c("Authors","DiagnosisDetails","FeatureCorrelation","SAMPLE_SIZE_SZ","EffectSize", "Variance","StandardError")]
    
    overall.row = matrix(c("SUMMARY","Sum", NA, NA, MetaforM$b, MetaforM$se^2, MetaforM$se), nrow = 1)
    overall.row.df = as.data.frame (overall.row)
    names(overall.row.df) = names(d2)
    d2=rbind(as.data.frame(d2), overall.row.df)
    
    #Make sure everything that is numeric is numeric, and everything that is a factor is a factor
    
    d2$EffectSize = as.numeric (d2$EffectSize)
    d2$Variance = as.numeric (d2$Variance)
    d2$StandardError = as.numeric(d2$StandardError)
    d2$DiagnosisDetails = as.factor (d2$DiagnosisDetails)
    d2$DiagnosisDetails <- relevel(d2$DiagnosisDetails,"SZ")
    
    #Calculate 95% CI values
    d2$lowerci = (-1.96*d2$StandardError)+d2$EffectSize
    d2$upperci = (1.96*d2$StandardError)+d2$EffectSize 
    
    #Calculate lowest, uppest and range of CI to delimitate the plot  
    lowest.ci <- min(d2$lowerci)
    uppest.ci <- max(d2$upperci)
    range_tot <- abs(lowest.ci) + abs(uppest.ci) 
    
    # make a plot
    p=ggplot(d2, aes(y=Authors, x=EffectSize, xmin=lowerci, xmax=upperci))+ 
      geom_point(color = 'black')+
      #Add 'special' points for the summary estimates, by making them diamond shaped
      geom_point(data=subset(d2, DiagnosisDetails=='Sum'), color='black', shape=18, size=4)+
      #add the CI error bars
      geom_errorbarh(height=.1)+
      #Specify the limits of the x-axis and relabel it to something more meaningful
      scale_x_continuous(limits=c(lowest.ci-0.3,uppest.ci+(range_tot*0.25)), name='Correlation coefficient')+
      #Give y-axis a meaningful label
      ylab('Reference')+
      #Add a vertical dashed line indicating an effect size of zero, for reference
      geom_vline(xintercept=0, color='black', linetype='dashed')+
      #Create sub-plots (i.e., facets) based on levels of setting
      #And allow them to have their own unique axes (so authors don't redundantly repeat)
      facet_grid(DiagnosisDetails~., scales= 'free', space='free')
    
    # add a new line to the plot_matrix to add the annotation with the effect size 
    ann_text <- data.frame(Authors = 1, EffectSize = SumSize.ci.ub+0.35,lowerci = 1, upperci = 1, lab = SumSize_tot, DiagnosisDetails = factor("Sum",levels = c("SZ","Sum")))  
    
    # add the annotation with the effect size, justify it and add theme
    
    p <- p + geom_text(data = ann_text,label = SumSize_tot, hjust=0, size=4.5, fontface="bold", color = "black") + theme_bw() + theme(strip.background = element_blank(), strip.text.y = element_blank()) + theme(axis.title=element_text(face="bold",size="10",color="black"),axis.text=element_text(size=10,face="bold"))
    
    print(p)
    ggsave(paste0(Name,"F.svg",collapse=""), plot = p)
    
    }
    
    
     ggplot_Combined_Forest <- function(m=MetaforM, BrmM = BrmM, BrmM_Task = BrmM_Task, d = d_plot, Name){


  # reorder level of plot matrix 
    
  d$Task <- factor(d$Task,levels = c("SOCIAL","SOC","FREE","FR","CONSTR","CON","SUM")) 
   
 # make sure everything is numeric is numeric
 
  d$Bayes_Effect_Size <- as.numeric(d$Bayes_Effect_Size)
  d$Bayes_Lower_CI <- as.numeric(d$Bayes_Lower_CI)
  d$Bayes_Upper_CI <- as.numeric(d$Bayes_Upper_CI)
 
 # crete a label variable with effect size and CI for ggplot 
  
 d$label <- paste0(round(d$Bayes_Effect_Size, digit = 3)," [",round(d$Bayes_Lower_CI,digit=3),", ",round(d$Bayes_Upper_CI, digit = 3),"]")
  
 #new line in the matrix for distinguishing studies with more than a task
  for (i in unique(d$ID)){
    d$temp[d$ID==i] <-seq(nrow(d[d$ID==i,])) 
  }
  
  d$ID1 <- with(d, paste0(ID,"_", temp))
  
  
  #Calculate lowest, uppest and range of CI to delimitate the plot
  
  lowest.ci <- as.numeric(min(d$Bayes_Lower_CI))
  uppest.ci <- as.numeric(max(d$Bayes_Upper_CI))
  range_tot <- abs(lowest.ci) + abs(uppest.ci) 
  
  Name_new = capitalize(Name)
  
  # and now the plot

   p_1=ggplot(d, aes(y=new_authors, x=Bayes_Effect_Size, xmin=Bayes_Lower_CI, xmax=Bayes_Upper_CI)) + 
    geom_point(color = 'black') +# Add data points and color them black
    geom_point(data=subset(d, DiagnosisDetails=='Sum'), color='black', shape=18, size=6) + # add diamond for summary estimate
    geom_errorbarh(height=.1) +# add the CI error bars
    geom_errorbarh(data=subset(d, DiagnosisDetails=='Sum'), height=.1, size = 1)+
    scale_x_continuous(limits=c(lowest.ci-0.1,uppest.ci+(range_tot*0.15)), name='Standardized Mean Difference (d)') +
    ylab('Reference') + 
    geom_vline(xintercept=0, color='black', linetype='dashed')+ # Add reference line at 0
    facet_grid(Task~., scales= 'free', space='free', margins = 'true')+
    theme(strip.text = element_text(face="bold", size=3,lineheight=5.0))
    
     # plot without error bars for manual editing
   
   p_2=ggplot(d, aes(y=new_authors, x=Bayes_Effect_Size, xmin=Bayes_Lower_CI, xmax=Bayes_Upper_CI)) + 
    geom_point(color = 'black') +# Add data points and color them black
    geom_point(data=subset(d, DiagnosisDetails=='Sum'), color='black', shape=18, size=6) + # add diamond for summary estimate
    scale_x_continuous(limits=c(lowest.ci-0.1,uppest.ci+(range_tot*0.25)), name='Standardized Mean Difference (d)') +
    ylab('Reference') + 
    geom_vline(xintercept=0, color='black', linetype='dashed')+ # Add reference line at 0
    facet_grid(Task~., scales= 'free', space='free', margins = 'true')+
    theme(strip.text = element_text(face="bold", size=8,lineheight=5.0))

   
  # add label to the plot with ES and CI for each line and add new theme

 p_def_1 <-   p_1+geom_text(data=d, aes(label = label,  x =uppest.ci+(range_tot*0.1)),  size=3.5,  color = "black")+
         theme_bw()+ 
          theme(panel.grid.major = element_blank(), 'panel.grid.minor' = element_blank())
 

 ggsave(paste0(Name,"Freq.png",collapse=""), plot = p_def_1, dpi ="retina",  width =32, height = 16, units = "cm")
 
 
   p_for_editing <-   p_2+geom_text(data=d, aes(label = label,  x =uppest.ci+(range_tot*0.115)),  size=5,  color = "black")+
    ggtitle(Name_new)+
         theme_bw()+ 
          theme(plot.title = element_text(size = 20, face = "bold", hjust = 0.5), axis.text.y = element_text(face="bold", size=16.2), strip.text = element_text(face="bold", size=10,lineheight=8.0), panel.grid.major = element_blank(), 'panel.grid.minor' = element_blank())
  

   ggsave(paste0(Name,"Freq_for_editing.tiff",collapse=""), plot = p_for_editing, dpi ="retina",  width =30, height = (log(nrow(d),base = 1.5))*3, units = "cm")
  
  
   
return(p_def_1)
 
  }
    
    
    
    ggplot_Freq_Forest(MetaforM,d)
    
    
    # Bayesian reproduction of the Random Effects Models
    
    prior = c(
      prior(normal(0,0.3),class=Intercept),
      prior(normal(0,0.3),class=sd)
    )
    formula_m<-bf(EffectSize | se(StandardError) ~ 1 + (1|new_authors))
    
    BrmM <- brmFitAndSave(formula_m,Name,d,prior=T,priorSpec=prior)
    forest_bayesian <- brmstools::forest(BrmM, grouping = "new_authors", digits=3, scale = 0.7, sort = "FALSE", show_data = T)
    print(forest_bayesian)
    ggsave(paste0(Name,"B.tiff",collapse=""), plot = forest_bayesian,dpi ="retina",  width =30, height = 16, units = "cm")
    
  
    d_plot <- d
    
    # select relevant variables
    
    d_plot <- d_plot[,c("ID","DiagnosisDetails","Authors","Population","Task","FeatureCorrelation","SAMPLE_SIZE_SZ","EffectSize","Variance","StandardError","new_authors")]
    
    # extract posterior estimates (ES and CI) for each single study and put them in the plot matrix 
    
    brm_estim <- as.data.frame(BrmM %>%
    spread_draws(b_Intercept,r_new_authors["01_Alpert.et.al..(2000)",]) %>%
    mutate(condition_mean = b_Intercept + r_new_authors) %>%
    median_qi(condition_mean))
    
    colnames(brm_estim)[1] <- "new_authors"
    brm_estim$new_authors <- gsub("\\."," ",brm_estim$new_authors)
    brm_estim$new_authors <- gsub("et al ","et al.",brm_estim$new_authors)
     
  d_plot  <-   merge(d_plot ,brm_estim[,c("condition_mean",".lower",".upper","new_authors")], by = "new_authors")
  
  colnames(d_plot )[12] <- "Bayes_Effect_Size"
  colnames(d_plot )[13] <- "Bayes_Lower_CI"
  colnames(d_plot )[14] <- "Bayes_Upper_CI"
  
  # reorder columns of the matrix
  
   d_plot  <- d_plot %>%select(-1,everything())  
   u = 11:13
   d_plot  <- d_plot %>%select(-u,everything())  
   
   #create new line in plot matrix with summary effect size
   
  overall.row = matrix(c("Summary", "Sum","Sum",NA, "SUM",NA,NA, fixef(BrmM)[1], (fixef(BrmM)[2])^2,fixef(BrmM)[2],"Summary Total",fixef(BrmM)[1], fixef(BrmM)[3],fixef(BrmM)[4]), nrow = 1)
  overall.row.df = as.data.frame (overall.row)
  names(overall.row.df) = names(d_plot)
  d_plot=rbind(as.data.frame(d_plot), overall.row.df)
  
  d_plot$DiagnosisDetails <- relevel(as.factor(d_plot$DiagnosisDetails),"SZ")
  d_plot$Task = as.factor(d_plot$Task)
  d_plot$Authors= as.factor(d_plot$Authors)
    
    
    
    # Test for influential factors
  
    inf <- cooks.distance(MetaforM)
    Number=sum(inf>1 & !is.na(inf))
    
    # If any such study is found identify them, report and re-run the analysis with clean data
    
    if (Number>0){
      InfName=names(inf[inf>1])
      d2 <- d %>% subset (!(Name %in% InfName))
      InfName=paste0(InfName,collapse="; ")
      MetaforM2 <- rma(EffectSize, Variance, data = d2, slab=Authors
                       )
      #res_cleanCI <- predict(MetaforM2,digits=3)
      #res_cleanCI2 <-confint(MetaforM2)
      
      BrmM2 <- brmFitAndSave(formula_m,Name,d2,prior=T,priorSpec=prior)
      
    } 
    
    ### funnel plot
    print(funnel(MetaforM, main = "Random-Effects Model",xlab = "Standardized Mean Difference"))
    #Tests for publication bias
    Bias <- ranktest(MetaforM)
    
 
  # Extract relevant estimates for the Bayesian model (BrmM) and calculate relevant stats (Q-stats, publiation bias, influential studies)
    
  EffSize <- round(fixef(BrmM)[1], 3)
    EffCI1 <- round(fixef(BrmM)[3], 3)
    EffCI2 <- round(fixef(BrmM)[4], 3)
    EffP <- round(MetaforM$pval, 3)
    if (EffSize>0){
    EvidenceRatio <- round(hypothesis(BrmM, "Intercept>0")$hypothesis$Evid.Ratio, 3)
    Credibility <- round(hypothesis(BrmM, "Intercept>0")$hypothesis$Post.Prob, 3)
    } else {
      EvidenceRatio <- round(hypothesis(BrmM, "Intercept<0")$hypothesis$Evid.Ratio, 3)
    Credibility <- round(hypothesis(BrmM, "Intercept<0")$hypothesis$Post.Prob, 3)
    
    }
    Sigma2 <- round(mean(posterior_samples(BrmM, pars = "^sd_")$sd_new_authors__Intercept ^ 2), 3)
    Sigma2CI1 <- round(quantile(posterior_samples(BrmM, pars = "^sd_")$sd_new_authors__Intercept ^ 2, 0.025), 3)
    Sigma2CI2 <- round(quantile(posterior_samples(BrmM, pars = "^sd_")$sd_new_authors__Intercept ^ 2, 0.975), 3)
  
  print(paste0("Hierarchical Bayesian meta-analysis revealed an overall estimated raw coefficient (Pearson' r) in ",Name," of ", EffSize, " (95% CI = ", EffCI1, ", ", EffCI2, ", p = ", EffP, ", evidence ratio = ", EvidenceRatio, ", credibility = ", Credibility, "%) with an overall variance between studies (sigma squared) of ", Sigma2, "  (95% CI = ", Sigma2CI1, ", ", Sigma2CI2, ")."))
  
  if (MetaforM$QEp<0.05){
    print(paste0("The variance in effects between studies could not be reduced to random sample variability between studies (Q-stats: ", round(MetaforM$QE,3),", p = ",round(MetaforM$QEp,3),")."))
  } else {
    print(paste0("The variance in effects between studies could be reduced to random sample variability between studies (Q-stats: ", round(MetaforM$QE,3),", p = ",round(MetaforM$QEp,3),")."))
  }
  
  if (Number==0) {
    print("No study was found to be influential.")
    
  } else {
    
    EffSize <- round(fixef(BrmM2)[1], 3)
    EffCI1 <- round(fixef(BrmM2)[3], 3)
    EffCI2 <- round(fixef(BrmM2)[4], 3)
    EffP <- round(MetaforM2$pval, 3)
    if (EffSize>0){
    EvidenceRatio <- round(hypothesis(BrmM2, "Intercept>0")$hypothesis$Evid.Ratio, 3)
    Credibility <- round(hypothesis(BrmM2, "Intercept>0")$hypothesis$Post.Prob, 3)
    } else {
      EvidenceRatio <- round(hypothesis(BrmM2, "Intercept<0")$hypothesis$Evid.Ratio, 3)
    Credibility <- round(hypothesis(BrmM2, "Intercept<0")$hypothesis$Post.Prob, 3)
    
    }
    Sigma2 <- round(mean(posterior_samples(BrmM2, pars = "^sd_")$sd_new_authors__Intercept ^ 2), 3)
    Sigma2CI1 <- round(quantile(posterior_samples(BrmM2, pars = "^sd_")$sd_new_authors__Intercept ^ 2, 0.025), 3)
    Sigma2CI2 <- round(quantile(posterior_samples(BrmM2, pars = "^sd_")$sd_new_authors__Intercept ^ 2, 0.975), 3)
    
    if (Number == 1) {
      print(
        paste0(
          "One study [", InfName, "] was found to be influential. Removing such study yielded an overall estimated coefficient of ",
          EffSize, " (95% CI: ", EffCI1, ", ", EffCI2,", p = ",
          EffP, ", evidence ratio = ", EvidenceRatio, ", credibility = ", Credibility, "%) with an overall variance between studies (sigma squared) of ", Sigma2, "  (95% CI = ", Sigma2CI1, ", ", Sigma2CI2, ")."))
      
    } else {
      print(
        paste0(
          Number," studies [", InfName, "] were found to be influential. Removing such studies yielded an overall estimated coefficient of ",
          EffSize," (95% CI: ", EffCI1,", ", EffCI2,", p = ",EffP, ", evidence ratio = ", EvidenceRatio, ", credibility = ", Credibility, "%) with an overall variance between studies (sigma squared) of ", Sigma2, "  (95% CI = ", Sigma2CI1, ", ", Sigma2CI2, ")."))
    }
  }
  if (Bias$pval>0.05){
    print(paste0("The data did not reveal any likely publication bias (Kendall's tau = ", round(Bias$tau,3), ", p = ", round(Bias$pval,3),")."))
  } else {
    print(paste0("The data revealed a likely publication bias (Kendall's tau = ", round(Bias$tau,3), ", p = ", round(Bias$pval,3),")."))
  }
  
  # Testing for the effect of task
  
    if (length(unique(d$Task))==1){
      print("Not enough data on Task to run a model")
    } else if (length(unique(d$Task))>1){
      
      MetaforM_Task <- rma.mv(EffectSize, Variance, random = ~ 1 + Task |ID, mods = ~ 1 + Task, method = "ML", data = d, slab = ID)
      
      prior = c(
        prior(normal(0,0.3),class=Intercept),
        prior(normal(0,0.3),class=b),
        prior(normal(0,0.3),class=sd)
      )
      formula_task<-bf(EffectSize | se(StandardError) ~ 1 + Task + (1 + Task |ID))
      BrmM_Task <- brmFitAndSave(formula_task,paste0(Name,"Task"),d,prior=T,priorSpec=prior)
      ICs <- compare_ic(BrmM,BrmM_Task)
      Weights <- model_weights(BrmM,BrmM_Task)
      
      
        forest_task <- brmstools::forest(BrmM_Task,  digits=3, scale = 0.7)
      
      print(forest_task)
      
          ggsave(paste0(Name,"B_task.svg",collapse=""), plot = forest_task,dpi ="retina",  width =30, height = 16, units = "cm")
          
     
      post<-posterior_samples(BrmM_Task)
      
      if (ICs$ic_diffs__[[1]]>=0){
        
         print(BrmM_Task)
        
          # Create a new model to be used only for graph editing   

          
           formula_m_prova_2 <-bf(EffectSize  ~ (1|Task)  )
    BrmM_prova_2 <- brmFitAndSave(formula_m_prova_2,Name,d,prior=T,priorSpec=prior)
    
    forest_prova <- brmstools::forest(BrmM_prova_2,  digits=3, scale = 0.7)
    print(forest_prova)
    ggsave(paste0(Name,"B_task_random.tiff",collapse=""), dpi ="retina",plot = forest_prova)
  
    
    # update the plot matrix with  summary effect sizes and CIs for each task group 
    
     if ("CONSTR" %in% unique(d$Task)){ 
         
       
  fixef_constrained  <- as.numeric(toString(summary(post$b_Intercept)[[4]]))
    
  constrained.ci.lb  <- as.numeric(toString(round(quantile(post$b_Intercept, c(0.025))[[1]], 3)))
    
  constrained.ci.ub <- as.numeric(toString(round(quantile(post$b_Intercept, c(0.975))[[1]], 3)))
        
  
  
         taskconstrained.row = matrix(c("Constrained_Sum", "Constrained_Sum","Constrained_Sum",NA, "CON",NA,NA, fixef_constrained, NA,NA,"Summary Constrained", fixef_constrained,constrained.ci.lb, constrained.ci.ub), nrow = 1)
         
   taskconstrained.row = as.data.frame (taskconstrained.row)
   names(taskconstrained.row) = names(d_plot)
   d_plot=rbind(as.data.frame(d_plot), taskconstrained.row)
   
      }
        
        if ("CONSTR" %in% unique(d$Task) & "FREE" %in% unique(d$Task)){
          
  fixef_free <- as.numeric(toString(round(summary(post$b_Intercept + post$b_TaskFREE)[[4]], 3)))
  
  free.ci.ub <-  as.numeric(toString(round(quantile(
                post$b_Intercept + post$b_TaskFREE, c(0.975)
              )[[1]], 3)))
  
  free.ci.lb <- as.numeric(toString(round(quantile(
                post$b_Intercept + post$b_TaskFREE, c(0.025)
              )[[1]], 3)))
          
  
   taskfree.row = matrix(c("Free_Sum", "Free_Sum","Free_Sum",NA, "FR",NA,NA, fixef_free, NA,NA,"Summary Free",fixef_free,free.ci.lb, free.ci.ub), nrow = 1)
   taskfree.row = as.data.frame (taskfree.row)
   names(taskfree.row) = names(d_plot)
   d_plot=rbind(as.data.frame(d_plot), taskfree.row)
  
          
        }
  
        if ("CONSTR" %in% unique(d$Task) & "SOCIAL" %in% unique(d$Task)){
          
           fixef_social <- as.numeric(toString(round(summary(post$b_Intercept + post$b_TaskSOCIAL)[[4]], 3)))
                                      
   social.ci.lb <- as.numeric(toString(round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.025)
              )[[1]], 3)))
   
   social.ci.ub <- as.numeric(toString(round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.975)
              )[[1]], 3)))
   
   tasksocial.row = matrix(c("Social_Sum", "Social_Sum","Social_Sum",NA, "SOC",NA,NA,fixef_social,NA,NA, "Summary Social",fixef_social,social.ci.lb , social.ci.ub ), nrow = 1)
   tasksocial.row = as.data.frame (tasksocial.row)
   names(tasksocial.row) = names(d_plot)
   d_plot=rbind(as.data.frame(d_plot), tasksocial.row)
   
        }
        
        if ("FREE" %in% unique(d$Task) & "SOCIAL" %in% unique(d$Task) & !("CONSTR" %in% unique(d$Task))){
          
    fixef_free  <- as.numeric(toString(summary(post$b_Intercept)[[4]]))
    
     free.ci.lb <- as.numeric(toString(round(quantile(post$b_Intercept, c(0.025))[[1]], 3)))
    
    free.ci.ub <- as.numeric(toString(round(quantile(post$b_Intercept, c(0.975))[[1]], 3)))
  
  
           fixef_social <- as.numeric(toString(round(summary(post$b_Intercept + post$b_TaskSOCIAL)[[4]], 3)))
                                      
   social.ci.lb <- as.numeric(toString(round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.025)
              )[[1]], 3)))
   
   social.ci.ub <- as.numeric(toString(round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.975)
              )[[1]], 3)))
   
   
    tasksocial.row = matrix(c("Social_Sum", "Social_Sum","Social_Sum",NA, "SOC",NA,NA,fixef_social,NA,NA, "Summary Social",fixef_social,social.ci.lb , social.ci.ub), nrow = 1)
 
   tasksocial.row = as.data.frame (tasksocial.row)
   names(tasksocial.row) = names(d_plot)
   d_plot=rbind(as.data.frame(d_plot), tasksocial.row)
   
   taskfree.row = matrix(c("Free_Sum", "Free_Sum","Free_Sum",NA, "FR",NA,NA, fixef_free, NA,NA,"Summary Free",fixef_free,free.ci.lb, free.ci.ub), nrow = 1)
   taskfree.row = as.data.frame (taskfree.row)
   names(taskfree.row) = names(d_plot)
   d_plot=rbind(as.data.frame(d_plot), taskfree.row)
        
      }
    }
    
    # and now test if adding task improve the model fit and print results
      
      
      
      if (ICs$ic_diffs__[[1]]<0){
        print(paste0("Adding task does not improve the model (Akaike weight: ", round(Weights[[2]]*100,0),")."))
      } else {
        print(paste0("Adding speech task to the model credibly improved it (Akaike weight: ", round(Weights[[2]])*100,"%)."))
       
      if ("CONSTR" %in% unique(d$Task)){ 
         
        print("Stats for CONSTRAINED")
        print(
          paste0(
            "Constrained monologic speech showed an effect of ",
            round(summary(post$b_Intercept)[[4]], 3),
            " (95% CI = ",
            round(quantile(post$b_Intercept, c(0.025))[[1]], 3),
            ", ",
            round(quantile(post$b_Intercept, c(0.975))[[1]], 3),
            ")."
          )
        )
        
      }
        
        if ("CONSTR" %in% unique(d$Task) & "FREE" %in% unique(d$Task)){
          print("Stats for FREE")
          print(
            paste0(
              "Free monologic speech showed an effect of ",
              round(summary(post$b_Intercept + post$b_TaskFREE)[[4]], 3),
              " (95% CI = ",
              round(quantile(
                post$b_Intercept + post$b_TaskFREE, c(0.025)
              )[[1]], 3),
              ", ",
              round(quantile(
                post$b_Intercept + post$b_TaskFREE, c(0.975)
              )[[1]], 3),
              ") compared to constrained monologue."
            )
          )
          print(hypothesis(BrmM_Task,"TaskFREE > 0"))
          
 }
  
        if ("CONSTR" %in% unique(d$Task) & "SOCIAL" %in% unique(d$Task)){
          print("Stats for SOCIAL")
          print(
            paste0(
              "Dialogic speech showed an effect of ",
              round(summary(post$b_Intercept + post$b_TaskSOCIAL)[[4]], 3),
              " (95% CI = ",
              round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.025)
              )[[1]], 3),
              ", ",
              round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.975)
              )[[1]], 3),
              ") compared to constrained monologue."
            )
          )
          print(hypothesis(BrmM_Task,"TaskSOCIAL > 0"))
          
          
        }
        
        if ("FREE" %in% unique(d$Task) & "SOCIAL" %in% unique(d$Task) & !("CONSTR" %in% unique(d$Task))){
          
            print("Stats for FREE")
        print(
          paste0(
            "Free monologic speech showed an effect of ",
            round(summary(post$b_Intercept)[[4]], 3),
            " (95% CI = ",
            round(quantile(post$b_Intercept, c(0.025))[[1]], 3),
            ", ",
            round(quantile(post$b_Intercept, c(0.975))[[1]], 3),
            ")."
          )
        )
          
          print("Stats for SOCIAL")
          print(
            paste0(
              "Dialogic speech showed an effect of ",
              round(summary(post$b_Intercept + post$b_TaskSOCIAL)[[4]], 3),
              " (95% CI = ",
              round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.025)
              )[[1]], 3),
              ", ",
              round(quantile(
                post$b_Intercept + post$b_TaskSOCIAL, c(0.975)
              )[[1]], 3),
              ") compared to free monologue."
            )
          )
          print(hypothesis(BrmM_Task,"TaskSOCIAL > 0"))
          
          
        }
        
        
           
      }
      
      plotCombined <- ggplot_Combined_Forest(MetaforM, BrmM, BrmM_Task, d_plot, Name)
    }
    
  }
  
  MetaPrior=data.frame(Name,Mean=EffSize,SE=fixef(BrmM)[2],SD=sqrt(Sigma2))
  return(MetaPrior) 
   
}

```



## Negative symptoms and and pitch mean

```{r, message=FALSE, warning=FALSE}

# Now perform the meta-analysis for correlation between each acoustic feature and symptoms clinical ratings

MetaAnalysisCorrelation(d,Name="negative symptoms and mean pitch",FeatureCorrelation="NEG_F0_MEAN")
```


## Positive symptoms and pitch mean
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="positive symptoms and mean pitch",FeatureCorrelation="POS_F0_MEAN")
```


## Alogia and pitch variability
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="alogia and pitch variability",FeatureCorrelation="ALOGIA_F0_SD")
```

## Flat affect and pitch variability
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="flat affect and pitch variability",FeatureCorrelation="FLAT_F0_SD")
```

## Negative symptoms and pitch variability
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="negative symptoms and pitch variability",FeatureCorrelation="NEG_F0_SD")
```

## Positive symptoms and pitch variability
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="positive symptoms and pitch variability",FeatureCorrelation="POS_F0_SD")
```

## Total and pitch variability
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="total psychopathology and pitch variability",FeatureCorrelation="TOT_F0_SD")
```

## Flat affect and intensity variability
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="flat affect and intensity variability",FeatureCorrelation="FLAT_INTENSITY_SD")
```

## Alogia and proportion of spoken time 
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="alogia and proportion of spoken time ",FeatureCorrelation="ALOGIA_SP_PERC")
```
## Flat affect and proportion of spoken time 
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="flat affect and proportion of spoken time ",FeatureCorrelation="FLAT_SP_PERC")
```
## Negative symptoms and proportion of spoken time 
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="negative symptoms and proportion of spoken time ",FeatureCorrelation="NEG_SP_PERC")
```

## Total and proportion of spoken time 
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="total psychopathology and proportion of spoken time ",FeatureCorrelation="TOT_SP_PERC")
```

## Negative symptoms and pause duration
```{r, message=FALSE, warning=FALSE}
MetaAnalysisCorrelation(d,Name="negative symptoms and pause duration",FeatureCorrelation="NEG_PAUSE_DUR")
```
